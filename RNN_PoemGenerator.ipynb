{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqwvLrYrl_gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM \n",
        "from keras.callbacks import LambdaCallback \n",
        "from keras import metrics\n",
        "\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCQsj1WomMkr",
        "colab_type": "code",
        "outputId": "29e5be83-f6a7-469a-dde8-1287a8b1da33",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "# Load data into x and y for RNN, and give maps to and from chars\n",
        "def parse_chars(text, seq_len, n_skip=1):\n",
        "    # Convert text to list of limes\n",
        "    lines = text.split('\\n')\n",
        "    \n",
        "    # Define text_r as the reduced text variable, which is a single string containing all chars in order\n",
        "    text_r = \"\"\n",
        "    # For every line\n",
        "    for line in lines:\n",
        "        # If the length is greater than 1 (skipping the only new-line lines)\n",
        "        if len(line) >= 1:\n",
        "            # If there is no number in the line (skipping all the lines with the numbers)\n",
        "            if not any(char.isdigit() for char in line):\n",
        "                # Remove the double space at the beginning of certain lines\n",
        "                if line[0] == ' ' and line[1] == ' ': \n",
        "                    line = line[2:]\n",
        "                # Add the line to the string\n",
        "                text_r = text_r + '\\n' + line\n",
        "    #text_r = text_r.lower()\n",
        "    # For counting the number of unique characters\n",
        "    n_chars = 0\n",
        "    # For converting from characters to indices\n",
        "    char_map = {}\n",
        "    # For converting from indices \n",
        "    char_map_r = {}\n",
        "    # For each character in our reduced text string\n",
        "    for char in (text_r):\n",
        "        # If the character is not already contained in the maps, add it\n",
        "        if char not in char_map:\n",
        "            char_map[char] = n_chars \n",
        "            char_map_r[n_chars] = char\n",
        "            # Add one unique character\n",
        "            n_chars += 1\n",
        "        \n",
        "    # Seqs takes every n_skip'th sequence to convert to x for training\n",
        "    seqs = []\n",
        "    # Takes the following character after seqs to convert to y for training\n",
        "    seq_next = []\n",
        "    \n",
        "    # Create list of 40-character sequences, starting with every n_skip'th character.\n",
        "    # Also store the following character\n",
        "    for i in range(0, len(text_r) - seq_len, n_skip):\n",
        "        seqs.append(text_r[i:i+seq_len])\n",
        "        seq_next.append(text_r[i+seq_len])\n",
        "        \n",
        "    # The number of sequences\n",
        "    N_seq = len(seqs)\n",
        "\n",
        "    # Defining x and y arrays\n",
        "    x = np.zeros((N_seq, seq_len, n_chars))\n",
        "    y = np.zeros((N_seq, n_chars))\n",
        "    \n",
        "    for i, seq in enumerate(seqs):\n",
        "        # Set the corresponding following character index to 1\n",
        "        y[i, char_map[seq_next[i]]] = 1\n",
        "        # Set each character in the sequence to 1 in its corresponding position (j)\n",
        "        for j, char in enumerate(seq):\n",
        "            x[i, j, char_map[char]] = 1\n",
        "    \n",
        "    return x, y, char_map, char_map_r\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff266320-c09f-4f0e-8c81-0d19e95da1ad\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ff266320-c09f-4f0e-8c81-0d19e95da1ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRuPdGQpmXJS",
        "colab_type": "code",
        "outputId": "869005d9-f8f1-4cc6-c9c6-dbbb83c44864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = open(os.path.join(os.getcwd(), 'shakespeare.txt')).read()\n",
        "# Define the length of character sequence of interest\n",
        "seq_len = 40\n",
        "# Define the n^th character to skip\n",
        "n_skip = 1\n",
        "# Parse the characters into trainable data\n",
        "x, y, char_map, char_map_r = parse_chars(text, seq_len, n_skip)\n",
        "# Count the number of unique characters\n",
        "n_chars = len(char_map)\n",
        "\n",
        "print(char_map)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, 'F': 1, 'r': 2, 'o': 3, 'm': 4, ' ': 5, 'f': 6, 'a': 7, 'i': 8, 'e': 9, 's': 10, 't': 11, 'c': 12, 'u': 13, 'w': 14, 'd': 15, 'n': 16, ',': 17, 'T': 18, 'h': 19, 'b': 20, 'y': 21, \"'\": 22, 'g': 23, 'v': 24, 'B': 25, 'p': 26, 'l': 27, 'H': 28, ':': 29, '-': 30, 'M': 31, 'k': 32, 'A': 33, 'W': 34, 'P': 35, '.': 36, 'z': 37, ';': 38, 'I': 39, 'S': 40, 'x': 41, 'L': 42, 'N': 43, 'D': 44, '?': 45, 'O': 46, 'C': 47, 'U': 48, 'q': 49, 'j': 50, 'R': 51, 'Y': 52, '(': 53, ')': 54, 'G': 55, 'V': 56, 'E': 57, 'K': 58, '!': 59, 'J': 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV7q7bJvmY1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model as sequential\n",
        "model = Sequential()\n",
        "# Add an LSTM with 128 units, and input shape corresponding to the sequence length \n",
        "# and the number of unique characters\n",
        "model.add(LSTM(192, input_shape=(seq_len, n_chars))) \n",
        "# Define dense layer output with softmax activation\n",
        "model.add(Dense(n_chars, activation='softmax'))\n",
        "# Define the model optimizer as RMSProp and the loss as categorical cross-entropy\n",
        "model.compile(optimizer='rmsprop',metrics=['acc'],loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur1AzHdNmbpz",
        "colab_type": "code",
        "outputId": "489d3a84-476b-40ae-c211-f5e1c7e94d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def sample(pred, temp=1.0):\n",
        "    # Credit to fchollet script posted on PIazza\n",
        "    # Take the predictions and convert them to an array of floats\n",
        "    pred = np.asarray(pred).astype('float64')\n",
        "    # Find the z_i values by taking the log, and divide by the temperatuer\n",
        "    pred = np.log(pred) / temp\n",
        "    # Take the exponent of the new probabilities, and divide them by the sum of probabilities\n",
        "    pred = np.exp(pred) / np.sum(np.exp(pred))\n",
        "    # Select the most-likely next character from this \n",
        "    return np.argmax(np.random.multinomial(1,pred,1))\n",
        "                     \n",
        "def on_epoch_end(epoch, _):\n",
        "    if epoch % 10 == 0: \n",
        "      # Credit to fchollet script posted on piazza\n",
        "      print()\n",
        "      print('........ After Epoch %d ........' % epoch)\n",
        "      # The length of the poem we wish to write following our first line\n",
        "      poem_len = 600\n",
        "      # For these 3 temperatuers\n",
        "      for temp in [1.5, 0.75, 0.25]: \n",
        "        print('................................')\n",
        "        print('........ Temperature %.1f ........' % temp)\n",
        "        # The first line of interest\n",
        "        sentence = \"Shall I compare thee to a summer's day?\\n\"\n",
        "        # Print the line, don't add another new line\n",
        "        print(sentence,end='')\n",
        "        # For the length of the poem \n",
        "        for i in range(poem_len):\n",
        "            # Get the corresponding x-values for the preceding characters we wish to \n",
        "            x_pred = np.zeros((1,seq_len, n_chars))\n",
        "            for j, char in enumerate(sentence):\n",
        "                x_pred[0, j, char_map[char]] = 1\n",
        "            \n",
        "            # Predict the output probabilities\n",
        "            pred = model.predict(x_pred, verbose=0)[0]\n",
        "            # Use these probabilities with the given temperature to find the \n",
        "            # index of the next character\n",
        "            next_idx = sample(pred,temp)\n",
        "            # Retrieve the next character from this index\n",
        "            next_char = char_map_r[next_idx]\n",
        "            \n",
        "            # Adjust the sentence to maintain its length, but encorporate the new character\n",
        "            sentence = sentence[1:] + next_char\n",
        "            # Print the new characters 1-by-1\n",
        "            print(next_char,end='')\n",
        "        print()\n",
        "        print('................................')\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "\n",
        "model.fit(x,y,batch_size=64,epochs=50,callbacks=[print_callback])\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "93634/93634 [==============================] - 131s 1ms/step - loss: 2.4257 - acc: 0.3188\n",
            "\n",
            "........ After Epoch 0 ........\n",
            "................................\n",
            "........ Temperature 1.5 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Thyeiu'd I 'hery Acey uepath agkinatc noushdWalen.\n",
            "du'sDy.\n",
            "heoiclciIusouthiflid,tI thtu  gpspe:.\n",
            "ond koyest or ard oucs bnd ben,vlendmocg diga:\n",
            "Thy wocu the stfi' enkftmey.\n",
            ",ha put le sle ewrena'aD.itulich fernotk foth kerss wefr oe yateO wevend rtkewesj\n",
            "yeswbhindisimy's ane I da to I the groget,\n",
            "Yit int-wrinite siyershogc nnlowrs nscigtind'ev bero\n",
            "I, bithors chyvured, watd whrield to s welfselNt'stilli-couet\n",
            "tiWhaswath eveonbro by sill ore cosi'se, geeisufegs aixly, neth,\n",
            "Wenpeplrns myasns\n",
            "' the,\n",
            " op dc vestls ficr t iwhadencbend lesee.\n",
            "B iethinnit gre silk munake, chorts sogcly main,i, mo Al\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.8 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "The gare sesty fimef thye not than seinise,\n",
            "And wiin an tharg sher st mect loven to nre theer,\n",
            "And forl to gald sheag thoe dore dith all carise dould fofdls in chels catinf Orerc,\n",
            "Thar the thico worbe thall.\n",
            "So fher thy ance ant shy shece fomy sealllid dide,\n",
            "My sea, then sund chereg-me with k will sorede,\n",
            "The, ne fring in therees in soll, no sher will weelises beeliet,\n",
            "And in s of lo noo dees ro ghene wors ore whim,\n",
            "That well cy cery ghenpice ine or by ariss oore.\n",
            "Anat st then or with st somy deenk goring,\n",
            "And and allwle the benct of sekend thtee, I eire gpaoll hathel crticl serus,\n",
            "Fuths aut v\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.2 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "That the sed the seall se the the ther thee ther seall,\n",
            "That  or the sere the ther ther sell se sellise,\n",
            "And the chen the sell the sere the thes thoul seare,\n",
            "And care the the sere the sell se and,\n",
            "And the se he the se the the the sere,\n",
            "The her the seare so the he the seand,\n",
            "And be the seand the sest the sear there here,\n",
            "That se the chere the sere the will se werise ther the bered,\n",
            "That the sere the sere the se the the core,\n",
            "The the se the seare se the with so thes sore,\n",
            "And my thy se the sere the hare the reed,\n",
            "And the the sellos sull the ther the se ther seall,\n",
            "And the the sell se the sere th\n",
            "................................\n",
            "Epoch 2/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 2.0029 - acc: 0.4167\n",
            "Epoch 3/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 1.8551 - acc: 0.4537\n",
            "Epoch 4/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.7547 - acc: 0.4793\n",
            "Epoch 5/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 1.6768 - acc: 0.4995\n",
            "Epoch 6/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.6141 - acc: 0.5137\n",
            "Epoch 7/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 1.5585 - acc: 0.5291\n",
            "Epoch 8/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 1.5082 - acc: 0.5422\n",
            "Epoch 9/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.4596 - acc: 0.5560\n",
            "Epoch 10/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 1.4126 - acc: 0.5688\n",
            "Epoch 11/50\n",
            "93634/93634 [==============================] - 117s 1ms/step - loss: 1.3675 - acc: 0.5818\n",
            "\n",
            "........ After Epoch 10 ........\n",
            "................................\n",
            "........ Temperature 1.5 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Asellges:lc theeres, my love thee agy wif'granige.\n",
            "By taurs o wnow hat my alp deserist\n",
            "Rst, foo time to kuce, bah ano't fore ptteex.\n",
            "Un are quay spernaly inuchatievancy:\n",
            "Sims'Tke not linctimi'iM, the wornd dad poplite:\n",
            "As onebulled, and kenvectity prubeing see,\n",
            "Wikan, what as bur farirehmines lowely,\n",
            "makis I torture which :\n",
            "wo ld weal eptrops mad lribe, rovaligatedof,\n",
            "And shown duth anwerer 'nguolinadedpuat:\n",
            "Frosd distatcon ky lives's sweepd with tome,\n",
            "Trioked, lete con. my vowcered hupes easd:\n",
            "resol bosh, desis tobbed yhur from clowinty lie.\n",
            "he rugons And looks at is blageed do ble,\n",
            "To bl, su\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.8 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "This for my love is not I sour see,\n",
            "May me that dead me so faithous stilles,\n",
            "I deather all thine opr with my stold,\n",
            "Whereis thou grose hild a do thou best ighory,\n",
            "To suck with thee with my me live is rease,\n",
            "That that you would hath untarly sunmed vied,\n",
            "And 'tis the wind, through they that mose that self your tweer:\n",
            "That have and therefore me bountion of the steech.\n",
            "Ah on the furgew for this, stare would to gue.\n",
            "That first of deathed to shill eyes do still,\n",
            "Live in other that that heaven thee part,\n",
            "To the were so leadd in hearthd spenged cares,\n",
            "The olders of those still can both goven,\n",
            "But wher\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.2 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Which his all the will be the strange thee,\n",
            "That they so forgured then thou the store,\n",
            "That then I am for my love to my mind,\n",
            "Since my self are to the strange the strenge,\n",
            "And so my self so thee is strange the strenge,\n",
            "And shall the world stol the summer all of true,\n",
            "And therefore though shall storns and therefore strings to deeds,\n",
            "And therefore strong the strange hat the stranged thee,\n",
            "The strangle all the strange these best to mine,\n",
            "When I have ston thee I am then the strenge,\n",
            "Then then I so form with thee thou shalt,\n",
            "To live thee when the storn the storn to me.\n",
            "Thou shall the see thou shalt\n",
            "................................\n",
            "Epoch 12/50\n",
            "93634/93634 [==============================] - 117s 1ms/step - loss: 1.3240 - acc: 0.5939\n",
            "Epoch 13/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.2832 - acc: 0.6058\n",
            "Epoch 14/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.2407 - acc: 0.6188\n",
            "Epoch 15/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.1989 - acc: 0.6298\n",
            "Epoch 16/50\n",
            "93634/93634 [==============================] - 117s 1ms/step - loss: 1.1615 - acc: 0.6409\n",
            "Epoch 17/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.1222 - acc: 0.6551\n",
            "Epoch 18/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 1.0873 - acc: 0.6654\n",
            "Epoch 19/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 1.0537 - acc: 0.6756\n",
            "Epoch 20/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 1.0208 - acc: 0.6849\n",
            "Epoch 21/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 0.9926 - acc: 0.6932\n",
            "\n",
            "........ After Epoch 20 ........\n",
            "................................\n",
            "........ Temperature 1.5 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "'rinoly lonsby yeselvy cleanned tyethoush,\n",
            "xrrome angeched time, or posturithed wfengshing ease,\n",
            ",ifna yem loss, ir, for deam'st be'e thomeralts rumikerce taal\n",
            "Not swayld even am it true rotkenly,\n",
            "Ant bad is Love, no recerwerl olokmessed near.\n",
            "Says -aftion his firdr rade my waition,,\n",
            "No, to pitcess of you, for untonnyyfeing,\n",
            "And my gravim il compersad diritay,\n",
            "Throughts' ind in, if fullosty cound, wif,\n",
            "Cxainst prass uhlaUtying loughs deprrise,\n",
            "Fareth youriw,\n",
            "adost tulos moutul ald dunoCheicays ackorTow,\n",
            "And it on fearhul, onny rn'antitn litines,\n",
            "so offy doth deaihes friend, and youth ialety la\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.8 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Thy with not fair I wind doth a thought shalt so,\n",
            "And hath my love sweet fould nor thee be old,\n",
            "Thou art all too must live you false wide.\n",
            "Hase partured fold ripup unth that hast,\n",
            "As grown to decainted buds a grow of elesh what stearp,\n",
            "In days make you be mine eye is preck,\n",
            "verse"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " of thee.\n",
            "If thou bear fair feartake have and hapest those,\n",
            "When all these paptarious past by mange,\n",
            "And all my hage of self addanting heavterest know,\n",
            "Though thou might I lest wrinkle know'st bake,\n",
            "O would have entaIned then as I shane,\n",
            "And sweaty adus trust report to die\n",
            "ve say,\n",
            "I doth times to willed and chance,\n",
            "Ip \n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.2 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "The warrs it to the reast to the cance,\n",
            "And they to summer's live the can all mand,\n",
            "And for a swear her face is true doth lie,\n",
            "That thou art fair from the proud of thee,\n",
            "That thou bear failts with heaven the rist,\n",
            "Then thought the praise them for my love seear,\n",
            "For I am not ever my thee mind eyes,\n",
            "That have by name the linured bainten shade,\n",
            "And therefore mayst in their praise the sleare,\n",
            "That heaven's are the world will beauty decay,\n",
            "The cossess to be of state of the day,\n",
            "And therefore to be ibsest that is in,\n",
            "And love not seem the death the with of trunes,\n",
            "And by thy self thy beauty thought \n",
            "................................\n",
            "Epoch 22/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 0.9662 - acc: 0.7026\n",
            "Epoch 23/50\n",
            "93634/93634 [==============================] - 120s 1ms/step - loss: 0.9402 - acc: 0.7090\n",
            "Epoch 24/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 0.9176 - acc: 0.7170\n",
            "Epoch 25/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 0.8957 - acc: 0.7232\n",
            "Epoch 26/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 0.8755 - acc: 0.7302\n",
            "Epoch 27/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 0.8553 - acc: 0.7376\n",
            "Epoch 28/50\n",
            "93634/93634 [==============================] - 119s 1ms/step - loss: 0.8401 - acc: 0.7396\n",
            "Epoch 29/50\n",
            "93634/93634 [==============================] - 118s 1ms/step - loss: 0.8247 - acc: 0.7455\n",
            "Epoch 30/50\n",
            "93634/93634 [==============================] - 117s 1ms/step - loss: 0.8082 - acc: 0.7501\n",
            "Epoch 31/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.7927 - acc: 0.7552\n",
            "\n",
            "........ After Epoch 30 ........\n",
            "................................\n",
            "........ Temperature 1.5 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "gift toneless, eyes, net would thou migittotitr\n",
            "by this commape,\n",
            "My upiens meiun plack's epersated pune,\n",
            "Which it my uly your flothoution shee,\n",
            "Which I prove fiese to wroth theeforebul mud,\n",
            "doth speaces erfoned in Burgeties fied,\n",
            "The oly must congonn, of ullaar th'e things seems\n",
            "Nor dyter gross wude of your becoude wishorith .\n",
            "He to pifed to true hourants to hem,\n",
            "And I is blase I sour gildless dew:\n",
            "nom thou behid, your lovies uses yet a y,\n",
            "cornimy the O world argaioty,\n",
            "Fregh when th'se, but you, you  abunot fonedn,\n",
            "loched terth eyts mes stronged tomes upe anive,\n",
            "To every wrinks remopepliny of \n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.8 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "I thought'st eless a With away, and thought,\n",
            "I must thou like that love be all and head,\n",
            "And place I whinke your ham that with mine eyes rain,\n",
            "resine eye'n my died be intentaft carr\n",
            "inght excess\n",
            "yet love to mistress' eyes are still wo tht dear:\n",
            "rost soouly care where to mort all to go,\n",
            "And truth of you, even to the praised truse.\n",
            ", beauty in their rodvey face, and summers truth so long,\n",
            "But say thy every this gave theire\n",
            "Ar falses there are for their ranking spate,\n",
            "I care she loven by their rettyel eprest,\n",
            "So is thou have, and therein love's fair still,\n",
            "The prey canused forgoting hiving fate,\n",
            "\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.2 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Thou art as that which it so stoulds and late,\n",
            "And the best canceled in their rotier place.\n",
            "O hem the drain affort to heary being,\n",
            "And to thy self thou lark the world to was,\n",
            "And to the senstance of thy wort's burn fair:\n",
            "Of thou whose black shawon, and there in thee,\n",
            "And thence shill will, where id so secume the rest,\n",
            "now for the pabling starp which thou destiled,\n",
            "And therefore with my self, but like to true,\n",
            "And portures that I with what when thou dost show,\n",
            "Where in eternit consenternofued,\n",
            "That thou shadow had, a foume I spiritht the worth,\n",
            "And poon the subject, and all your mine,\n",
            "Who is do\n",
            "................................\n",
            "Epoch 32/50\n",
            "93634/93634 [==============================] - 116s 1ms/step - loss: 0.7792 - acc: 0.7589\n",
            "Epoch 33/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.7681 - acc: 0.7631\n",
            "Epoch 34/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.7542 - acc: 0.7671\n",
            "Epoch 35/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.7432 - acc: 0.7701\n",
            "Epoch 36/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.7301 - acc: 0.7732\n",
            "Epoch 37/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.7200 - acc: 0.7776\n",
            "Epoch 38/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.7097 - acc: 0.7796\n",
            "Epoch 39/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.7016 - acc: 0.7829\n",
            "Epoch 40/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6867 - acc: 0.7886\n",
            "Epoch 41/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.6797 - acc: 0.7894\n",
            "\n",
            "........ After Epoch 40 ........\n",
            "................................\n",
            "........ Temperature 1.5 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Then have I tif, nor 'erstand ndamless year:\n",
            "Of hem it hel, inl's my dies presimy,\n",
            "Teem to he m yut, and out awsoon I amy,\n",
            "And truth they chemker wils, joddion igatune.\n",
            "uereft the leves to me, to haved drown,\n",
            "aindod, wils heallyines of your povi' netht.\n",
            "ver thou thy self forbod:\n",
            "I thou of some nigneds live infention.\n",
            "ceemberedburn of my sleet'stch durita\n",
            "Ingeary your feall-scordow mosery comela.\n",
            "Though infear facking on ourne -romemote.\n",
            "On uf thou lov'st tell thy ped, thou users'sp,\n",
            "Weiher 'eat'st which poetulier of such sun,\n",
            "If trut slefping sournkinature' olfteeming hast.\n",
            " alallyot before ta\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.8 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Then have I thought of lose, thou less to lend, never I ent.\n",
            "For to your praise shall be to me do esermem.\n",
            "That pour is destrment, correcter haid If men.\n",
            "I give the thine of sufful well so slone,\n",
            "To there cance doth that my adder hath my place.\n",
            "Nor thou thy sould, but feach there in thee,\n",
            "And pranse the storn, and unfalled bright,\n",
            "The owes knows flameated ard are sore would bory,\n",
            "Alt foind no wor, what soor to time dies,\n",
            "Then merit lime's poor poilous is my love,\n",
            "Then my thee mine own beauter sarr and feirs,\n",
            ",o's naguth dosp that the distard where.\n",
            "If pensuit frief, and therefore mayse matken,\n",
            "................................\n",
            "................................\n",
            "........ Temperature 0.2 ........\n",
            "Shall I compare thee to a summer's day?\n",
            "Then have I thought in on thy beauty thine?\n",
            "In thee I am golden of her price in this,\n",
            "The happien my exply ssee hate he sweet show,\n",
            "Then best is bleath that they even waste thee well,\n",
            "Than when I say gine and car so is deep,\n",
            "Where siect, ard there is not so should be.\n",
            "Thun then dy love thee to your me bothing,\n",
            "And the world-doscrupient some mistall hearted are,\n",
            "And the her micklined best accomprine,\n",
            "That I am not do I now for their his treasure,\n",
            "Wherein the gotyous veillit from accomaty,\n",
            "Which soully better and my lovely spend,\n",
            "The eye of yours, and your more dear look so.\n",
            "To move remomp, and \n",
            "................................\n",
            "Epoch 42/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6740 - acc: 0.7907\n",
            "Epoch 43/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6625 - acc: 0.7945\n",
            "Epoch 44/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.6543 - acc: 0.7955\n",
            "Epoch 45/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6477 - acc: 0.7993\n",
            "Epoch 46/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6355 - acc: 0.8018\n",
            "Epoch 47/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6308 - acc: 0.8038\n",
            "Epoch 48/50\n",
            "93634/93634 [==============================] - 114s 1ms/step - loss: 0.6258 - acc: 0.8053\n",
            "Epoch 49/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6174 - acc: 0.8086\n",
            "Epoch 50/50\n",
            "93634/93634 [==============================] - 115s 1ms/step - loss: 0.6076 - acc: 0.8097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbaca8bcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlRZ4TjmoAvq",
        "colab_type": "code",
        "outputId": "20009419-bd6d-4944-8f10-51e17f682867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "  sentence = \"Shall I compare thee to a summer's day?\\n\"\n",
        "  # Print the line, don't add another new line\n",
        "  print(sentence,end='')\n",
        "  poem_len = 800\n",
        "  # For the length of the poem \n",
        "  for i in range(poem_len):\n",
        "    # Get the corresponding x-values for the preceding characters we wish to \n",
        "    x_pred = np.zeros((1,seq_len, n_chars))\n",
        "    for j, char in enumerate(sentence):\n",
        "      x_pred[0, j, char_map[char]] = 1\n",
        "            \n",
        "    # Predict the output probabilities\n",
        "    pred = model.predict(x_pred, verbose=0)[0]\n",
        "    # Use these probabilities with the given temperature to find the \n",
        "    # index of the next character\n",
        "    next_idx = sample(pred,0.25)\n",
        "    # Retrieve the next character from this index\n",
        "    next_char = char_map_r[next_idx]\n",
        "            \n",
        "    # Adjust the sentence to maintain its length, but encorporate the new character\n",
        "    sentence = sentence[1:] + next_char\n",
        "    # Print the new characters 1-by-1\n",
        "    print(next_char,end='')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Thou art more blassed reaths of true mindsts,\n",
            "And in their parts of make the sweetest be.\n",
            "To thi"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "s that for my self, no bebled now,\n",
            "And for their praise therefore to be belong,\n",
            "Than when I partounes write of youns all,\n",
            "What it me tongues a proudest of thy self,\n",
            "So long as youth and thought that live and deed,\n",
            "ot shand excupse that the will be wear,\n",
            "That I in thee to live eye as eyes doth shand\n",
            "To stands of pursused say I say not live,\n",
            "And due to be, our changer beauty showe,\n",
            "They love hore, not so greet thee first with despite,\n",
            "The canker twaste, therefore to be belove.\n",
            "Thou mary blass might I thow that befored,\n",
            "And sweet some it but simpow restare some,\n",
            "When you love's discimed and his scord of wronght,\n",
            "And some theevil for a women's fast right,\n",
            "And may by lip than cheek the lovely gran\n",
            "Al"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVkgg0g3CpOA",
        "colab_type": "code",
        "outputId": "1c316a1f-53c3-454f-9f75-bd1cb066f98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "  sentence = \"Shall I compare thee to a summer's day?\\n\"\n",
        "  # Print the line, don't add another new line\n",
        "  print(sentence,end='')\n",
        "  poem_len = 800\n",
        "  # For the length of the poem \n",
        "  for i in range(poem_len):\n",
        "    # Get the corresponding x-values for the preceding characters we wish to \n",
        "    x_pred = np.zeros((1,seq_len, n_chars))\n",
        "    for j, char in enumerate(sentence):\n",
        "      x_pred[0, j, char_map[char]] = 1\n",
        "            \n",
        "    # Predict the output probabilities\n",
        "    pred = model.predict(x_pred, verbose=0)[0]\n",
        "    # Use these probabilities with the given temperature to find the \n",
        "    # index of the next character\n",
        "    next_idx = sample(pred,0.75)\n",
        "    # Retrieve the next character from this index\n",
        "    next_char = char_map_r[next_idx]\n",
        "            \n",
        "    # Adjust the sentence to maintain its length, but encorporate the new character\n",
        "    sentence = sentence[1:] + next_char\n",
        "    # Print the new characters 1-by-1\n",
        "    print(next_char,end='')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Thou art more from my farthess graces are spent.\n",
            "Than they of such their propiling he reffalow.\n",
            "To day that poor his image ade the past,\n",
            "of true hath found of loves, you althering, and sunstagetty,\n",
            "At still neve pay that in a thought to rehild.\n",
            "This that repert welf welled with to be,\n",
            "And that usI shor not better thee thingly night,\n",
            "And ours in lover's shong a feed, of least,\n",
            "of still every thal in his morrain age,\n",
            "To will in thee this gall, I defear die.\n",
            "If thou survive their spirit of their rehise,\n",
            "Then I hase cridned of a worthings strange,\n",
            "They with his bebuned how that sage of ill,\n",
            "That in her pose pleased thought from thee,\n",
            "Whi"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "le he isst praise him his istrace to main,\n",
            "And that it worth even back then dightcy,\n",
            "For shall now will my eye gowery yeth,\n",
            "And by a perfect forgot unon aman.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo_F5xvmDLv9",
        "colab_type": "code",
        "outputId": "c4f56d23-f9a5-4ca3-ffcb-8659e1056258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "  sentence = \"Shall I compare thee to a summer's day?\\n\"\n",
        "  # Print the line, don't add another new line\n",
        "  print(sentence,end='')\n",
        "  poem_len = 800\n",
        "  # For the length of the poem \n",
        "  for i in range(poem_len):\n",
        "    # Get the corresponding x-values for the preceding characters we wish to \n",
        "    x_pred = np.zeros((1,seq_len, n_chars))\n",
        "    for j, char in enumerate(sentence):\n",
        "      x_pred[0, j, char_map[char]] = 1\n",
        "            \n",
        "    # Predict the output probabilities\n",
        "    pred = model.predict(x_pred, verbose=0)[0]\n",
        "    # Use these probabilities with the given temperature to find the \n",
        "    # index of the next character\n",
        "    next_idx = sample(pred,1.5)\n",
        "    # Retrieve the next character from this index\n",
        "    next_char = char_map_r[next_idx]\n",
        "            \n",
        "    # Adjust the sentence to maintain its length, but encorporate the new character\n",
        "    sentence = sentence[1:] + next_char\n",
        "    # Print the new characters 1-by-1\n",
        "    print(next_char,end='')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Your inurestimy doth that I callue.\n",
            "Then aumeh mistard hrave , might by theirsearnyvits,\n",
            "Singl sumier watred with burbies ne due,\n",
            "That in they , less have prearour in any'st,\n",
            "'t spendy numm aflove of thine thou carts make Will,\n",
            "When thiugh ncees would goe, dver worsd aid,\n",
            "lespetion be, a dignivest utol the sumnors,\n",
            "Of this huicers and his scyined shows I live,\n",
            "Appan I the the batincqued's dwell mera:\n",
            "From shampered herp, tyonegh regimed best,\n",
            "co, I'el fame eyes If thee, when groan seef:\n",
            "O teast your wilt, nor for wo donsjuace,\n",
            " year feals primily sping,\n",
            "When ip in hum in him behold a ftwersting,\n",
            "lay spirit of eye's device more vainigued,\n",
            "In prove hear that deas rigats than beyon,\n",
            "Samethe hiseming summerts yours, worhings beartored,\n",
            "It righing tre givet for this gentles fair,\n",
            "tard torgmed a"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-ao2wuXDU5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}